\chapter{The rise of Large Language Models}

The advent of Large Language Models (LLMs) has initiated another profound shift in the NLP landscape. Their advanced reasoning and generation capabilities are redefining their role in the HMLC pipeline, moving them beyond being simple end-point classifiers to becoming integral co-pilots in various stages of the workflow.

\section{Zero shot and few-shot classification}
The most immediate impact of LLMs is their remarkable ability to perform classification tasks with little to no task-specific training data. Through in-context learning, an LLM can be prompted with a task description and a few examples (few-shot) or even no examples (zero-shot) and perform hierarchical multi-label classification. This capability represents a paradigm shift for low-resource scenarios, potentially obviating the need for extensive data collection and annotation efforts; for narrative detection, one can provide definitions of the target narratives and ask the LLM to classify a new document accordingly.~\cite{wang-etal-2023-text2topic}

For instance, Eljadiri and Nurbakova (2025) demonstrate a high-performing zero-shot agentic approach to narrative classification. Their system instantiates multiple specialized LLM agents, each responsible for a binary decision on a single narrative or subnarrative label, while a meta-agent aggregates the binary outputs into final multi-label predictions. The agents are orchestrated with AutoGen and operate without task-specific fine-tuning, which enables parallel detection across the two-level taxonomy; this design yielded competitive results on the SemEval-2025 test set and highlights the practical zero-shot LLM systems for complex hierarchical tasks.~\cite{eljadiri-nurbakova-2025-team}


\section{LLMs for data augmentation}
\label{sec:llm-augmentation}

One of the most promising applications of LLMs is in addressing data scarcity and class imbalance through synthetic data generation. An LLM can be prompted to act as a domain expert and generate new text samples for underrepresented (tail) classes. This can be done by paraphrasing existing examples to increase diversity or by generating entirely new, plausible examples from scratch. This approach offers a sophisticated and flexible alternative to traditional data augmentation techniques like synonym replacement or back-translation. \cite{cegin-etal-2025-llms,glazkova2024evaluating}

In more extreme cases; for example, a scenario with complete lack of labeled data, an LLM can be used to generate a large corpus of "weak" or "silver" labels. These labels, while imperfect, can serve as a starting point for training a smaller, more efficient model. Frameworks like JSDRV by Yang et al. (2024) take this a step further, using a reinforcement learning policy to select the highest-quality LLM-generated annotations for fine-tuning, creating a self-improving annotation and training pipeline \cite{yang-etal-2024-reinforcement}.

\section{LLMs as evaluation assistants}
For extreme multi-label classification tasks with thousands of labels, manual evaluation is prohibitively expensive and time-consuming. Li et al. (2023) aimed to compare a label-ranking BiCross-Encoder against a SciBERT classifier in a very large-label setting (11,486 labels) while lacking a ready human-annotated test set. They demonstrated a practical approach by asking ChatGPT to rate the relevance of candidate labels: for each document they fed the top-10 model-predicted labels to ChatGPT and requested a 3-point relevance score (0 = irrelevant, 1 = somewhat relevant, 2 = highly relevant) along with brief explanations. The authors treated these LLM judgments as automatic annotations to compare models, then spot-checked a sample with subject-matter experts and reported about 60\% agreement on the 3-point scale (rising to 82\% when collapsing 1 and 2 into a single ``relevant'' class). They conclude that using ChatGPT as an evaluation assistant is a cost- and time-efficient way to bootstrap evaluation when comprehensive human annotation is infeasible. \cite{li-etal-2023-enhancing-extreme}

